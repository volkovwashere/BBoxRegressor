{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('deep_learning': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8277c4497ec5ba7d6314982d6cc981d386d2f2b92a732db8e35c7edb9898c80e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "from cifar10_models import mobilenetv2\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Subset, DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Net = mobilenetv2.mobilenet_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for module in Net.modules():\n",
    "#    if isinstance(module, nn.BatchNorm2d):\n",
    "#        module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for param in Net.parameters():\n",
    "#    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()/1024**2, torch.cuda.memory_cached()/1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.2, inplace=False)\n",
       "  (1): Linear(in_features=1280, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "Net.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, train_x, train_y):\n",
    "        self.data = train_x \n",
    "        self.target = train_y \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, pretrainedModel):\n",
    "        super().__init__()\n",
    "        self.features = pretrainedModel.features\n",
    "        \n",
    "        self.Flatten = nn.Flatten()\n",
    "        self.FC1 = nn.Linear(20480, 128)\n",
    "        self.FC2 = nn.Linear(128, 64)\n",
    "        self.FC3 = nn.Linear(64, 32)\n",
    "        self.FC4 = nn.Linear(32, 32)\n",
    "\n",
    "\n",
    "        self.Dropout2D = nn.Dropout2d(p=0.2)\n",
    "        self.Dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "\n",
    "        self.outLayer1 = nn.Linear(32, 4)\n",
    "        #self.outLayer2 = nn.Linear(32, 4)\n",
    "        #self.outLayer3 = nn.Linear(32, 4)\n",
    "        #self.outLayer4 = nn.Linear(32, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.Dropout2D(self.features(x))\n",
    "        x = self.Flatten(x) # flatten out the last conv layer\n",
    "\n",
    "        x = self.Dropout(torch.selu(self.FC1(x)))# use dropout with p=0.2\n",
    "        x = self.Dropout(torch.selu(self.FC2(x)))\n",
    "        x = self.Dropout(torch.selu(self.FC3(x)))\n",
    "        x = self.Dropout(torch.selu(self.FC4(x)))\n",
    "\n",
    "        out1 = self.outLayer1(x)\n",
    "        #out2 = self.outLayer2(x)\n",
    "        #out3 = self.outLayer3(x)\n",
    "        #out4 = self.outLayer4(x)\n",
    "\n",
    "        return out1#, out2, out3, out4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.CIFAR10('../data-unversioned/p1ch7/', train=True, transform=preprocess, download=False)\n",
    "imgs = os.listdir('data/training')\n",
    "imgs.sort()\n",
    "indices = [int(name[0:5]) for name in imgs]\n",
    "my_subset = Subset(dataset, indices) #create subset based on indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "for data, label in my_subset:\n",
    "    train_x.append(data)\n",
    "train_x = torch.stack(train_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.from_numpy(np.load('data/labels.npy')).float()\n",
    "labels = labels.to(device=device)\n",
    "\n",
    "TrainSet = MyDataset(train_x, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[29.3383,  5.3111,  0.9465,  5.0000],\n",
       "        [ 5.0803, 13.2412,  4.5605,  2.1632],\n",
       "        [21.7605, 10.3194,  4.6590,  5.0000],\n",
       "        [13.8442, 19.0300,  5.0000,  5.0000]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "TrainSet[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(TrainSet, batch_size=64, shuffle=True) \n",
    "model = RegressionModel(Net).to(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 1)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5addd921388a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimgT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimgT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 1)"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('data/attacks/00000_input_img.png')\n",
    "imgT = torch.tensor(img)\n",
    "imgT = imgT.view(3, 32 , 32).to(device=device)\n",
    "imgT = torch.unsqueeze(imgT, 0).float()\n",
    "out1, out2, out3, out4 = model(imgT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "for batch, l in train_loader:\n",
    "    A = batch.to(device=device)\n",
    "    B = l\n",
    "    break\n",
    "\n",
    "A.shape\n",
    "B.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'arrange_labels_correctly' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e228b23d2ded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrange_labels_correctly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mIoULoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'arrange_labels_correctly' is not defined"
     ]
    }
   ],
   "source": [
    "d = arrange_labels_correctly(B)[0]\n",
    "IoULoss(A, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoULoss(predictions, ground_truth):\n",
    "    P_x = predictions[..., 0:1]\n",
    "    P_y = predictions[..., 1:2]\n",
    "    P_h = predictions[..., 2:3]\n",
    "    P_w = predictions[..., 3:4]\n",
    "    G_x = ground_truth[..., 0:1]\n",
    "    G_y = ground_truth[..., 1:2]\n",
    "    G_h = ground_truth[..., 2:3]\n",
    "    G_w = ground_truth[..., 3:4]\n",
    "\n",
    "    w_intersection = torch.min(P_x + P_w, G_x + G_w) - torch.max(P_x, G_x)\n",
    "    h_intersection = torch.min(P_y + P_h, G_y + G_h) - torch.max(P_y, G_y)\n",
    "    intersection = w_intersection.clamp(0) * h_intersection.clamp(0)#if no intersection, value will default to 0\n",
    "   \n",
    "    union = P_h * P_w + G_h * G_w - intersection\n",
    "    IoU = (intersection + 1e-6)/(union + 1e-6)\n",
    "\n",
    "    ##central points\n",
    "    central_p_x = (P_x + P_w)/2\n",
    "    central_p_y = (P_y + P_h)/2\n",
    "    central_l_x = (G_x + G_w)/2\n",
    "    central_l_y = (G_y + G_h)/2\n",
    "    euc_dist = torch.sqrt(torch.square(central_l_x - central_p_x) + torch.square(central_l_y - central_p_y))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #get diagional\n",
    "    w_union = torch.max(P_x + P_w, G_x + G_w) - torch.min(P_x, G_x)\n",
    "    h_union = torch.max(P_y + P_h, G_y + G_h) - torch.min(P_y, G_y)\n",
    "    c_diag = torch.sqrt(torch.square(w_union) + torch.square(h_union))\n",
    "\n",
    "    #penalty term\n",
    "    penalty_term = euc_dist/c_diag\n",
    "\n",
    "    DistanceIoULoss = 1 - IoU + penalty_term\n",
    "\n",
    "    return DistanceIoULoss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = IoULoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_labels_correctly(label_batch):\n",
    "    l1 = torch.stack([label[0] for label in label_batch])\n",
    "    l2 = torch.stack([label[1] for label in label_batch])\n",
    "    l3 = torch.stack([label[2] for label in label_batch])\n",
    "    l4 = torch.stack([label[3] for label in label_batch])\n",
    "\n",
    "    return l1, l2, l3, l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, loader, batch_size: int):    \n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        running_loss = 0.0\n",
    "        idx = 0\n",
    "        for img_batch, labels in loader:\n",
    "            img_batch = img_batch.to(device=device)\n",
    "            #out1, out2, out3, out4 = model(img_batch)\n",
    "            out1 = model(img_batch)\n",
    "            label1, label2, label3, label4 = arrange_labels_correctly(labels)\n",
    "            \n",
    "            loss1 = loss_fn(out1, label1)\n",
    "            #loss2 = loss_fn(out2, label2)\n",
    "            #loss3 = loss_fn(out3, label3)\n",
    "            #loss4 = loss_fn(out4, label4)\n",
    "\n",
    "            loss_total = loss1\n",
    "            #print(loss_total)\n",
    "            #loss_total = (loss1 + loss2 + loss3 + loss4)#accumulate loss \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_total.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss_total.item() * img_batch.size(0)\n",
    "            \n",
    "            if idx % 400 == 0:\n",
    "                print(f'step {idx} is the current iteration and loss is: {loss_total}')\n",
    "\n",
    "            idx += 1\n",
    "            \n",
    "        \n",
    "        epoch_loss = running_loss / len(TrainSet)\n",
    "        print(f'At epoch: {epoch}, the training loss is {epoch_loss}')\n",
    "        losses.append(epoch_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step 0 is the current iteration and loss is: 136.04183959960938\n",
      "At epoch: 1, the training loss is 95.42759398653872\n",
      "step 0 is the current iteration and loss is: 69.96180725097656\n",
      "At epoch: 2, the training loss is 44.0995752926168\n",
      "step 0 is the current iteration and loss is: 32.76673889160156\n",
      "At epoch: 3, the training loss is 38.354484032442286\n",
      "step 0 is the current iteration and loss is: 34.053314208984375\n",
      "At epoch: 4, the training loss is 36.44070301132736\n",
      "step 0 is the current iteration and loss is: 41.09621047973633\n",
      "At epoch: 5, the training loss is 35.108608035988695\n",
      "step 0 is the current iteration and loss is: 43.881492614746094\n",
      "At epoch: 6, the training loss is 33.77047997256925\n",
      "step 0 is the current iteration and loss is: 36.84600830078125\n",
      "At epoch: 7, the training loss is 32.77409259358629\n",
      "step 0 is the current iteration and loss is: 32.38523864746094\n",
      "At epoch: 8, the training loss is 31.51329566109653\n",
      "step 0 is the current iteration and loss is: 23.24835205078125\n",
      "At epoch: 9, the training loss is 30.537478644084143\n",
      "step 0 is the current iteration and loss is: 25.339664459228516\n",
      "At epoch: 10, the training loss is 29.49020987100866\n",
      "step 0 is the current iteration and loss is: 26.57282066345215\n",
      "At epoch: 11, the training loss is 27.975790069900327\n",
      "step 0 is the current iteration and loss is: 28.927539825439453\n",
      "At epoch: 12, the training loss is 26.828036245006814\n"
     ]
    }
   ],
   "source": [
    "training_loop(n_epochs=12, optimizer=optimizer, model=model, loss_fn=loss_fn, loader=train_loader, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step 0 is the current iteration and loss is: 1.3308002948760986\n",
      "At epoch: 1, the training loss is 1.3488286616111271\n",
      "step 0 is the current iteration and loss is: 1.3412375450134277\n",
      "At epoch: 2, the training loss is 1.3508517068903756\n",
      "step 0 is the current iteration and loss is: 1.3485198020935059\n",
      "At epoch: 3, the training loss is 1.3460980313850808\n",
      "step 0 is the current iteration and loss is: 1.3441489934921265\n",
      "At epoch: 4, the training loss is 1.341671674767616\n",
      "step 0 is the current iteration and loss is: 1.344853401184082\n",
      "At epoch: 5, the training loss is 1.3411050069021273\n",
      "step 0 is the current iteration and loss is: 1.3581230640411377\n",
      "At epoch: 6, the training loss is 1.3391160496670689\n",
      "step 0 is the current iteration and loss is: 1.334467887878418\n",
      "At epoch: 7, the training loss is 1.3361945206365369\n",
      "step 0 is the current iteration and loss is: 1.356292963027954\n",
      "At epoch: 8, the training loss is 1.3368911886710546\n",
      "step 0 is the current iteration and loss is: 1.3348350524902344\n",
      "At epoch: 9, the training loss is 1.3330693546684966\n",
      "step 0 is the current iteration and loss is: 1.3541555404663086\n",
      "At epoch: 10, the training loss is 1.3301864372665457\n",
      "step 0 is the current iteration and loss is: 1.3424742221832275\n",
      "At epoch: 11, the training loss is 1.3317521909093462\n",
      "step 0 is the current iteration and loss is: 1.3191040754318237\n",
      "At epoch: 12, the training loss is 1.3387213264553885\n",
      "step 0 is the current iteration and loss is: 1.3247466087341309\n",
      "At epoch: 13, the training loss is 1.33583239544138\n",
      "step 0 is the current iteration and loss is: 1.3188467025756836\n",
      "At epoch: 14, the training loss is 1.3369672423781847\n",
      "step 0 is the current iteration and loss is: 1.323482871055603\n",
      "At epoch: 15, the training loss is 1.3312557138374657\n",
      "step 0 is the current iteration and loss is: 1.3240944147109985\n",
      "At epoch: 16, the training loss is 1.3273562078433494\n",
      "step 0 is the current iteration and loss is: 1.3207346200942993\n",
      "At epoch: 17, the training loss is 1.3284263399058236\n",
      "step 0 is the current iteration and loss is: 1.3519322872161865\n",
      "At epoch: 18, the training loss is 1.3283912899991024\n",
      "step 0 is the current iteration and loss is: 1.3439133167266846\n",
      "At epoch: 19, the training loss is 1.3239188080296973\n",
      "step 0 is the current iteration and loss is: 1.336688756942749\n",
      "At epoch: 20, the training loss is 1.323488074211289\n"
     ]
    }
   ],
   "source": [
    "training_loop(n_epochs=20, optimizer=optimizer, model=model, loss_fn=loss, loader=train_loader, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = my_subset[5][0].to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgbatch, labels in train_loader:\n",
    "    o1 = model(imgbatch.to(device=device))\n",
    "    \n",
    "    asd = labels\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(o1, l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = torch.stack([a[0][:2] for a in asd])\n",
    "l1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels[0], l1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "del labels\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd2 = my_subset[0][0].to(device=device)\n",
    "asd3 = my_subset[84][0].to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[18.0107, 19.8563,  4.6095,  4.9596]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[11.8487, 14.1766,  3.0326,  3.6622]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>))"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "model(torch.unsqueeze(asd2, 0)), model(torch.unsqueeze(asd3, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_p = cv2.imread('data/training/00000_input_img.png')\n",
    "import matplotlib.patches as patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([29.3383,  5.3111,  0.9465,  5.0000], device='cuda:0'),\n",
       " tensor([ 5.4134, 20.7168,  3.7898,  0.9964], device='cuda:0'))"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "labels[0][0], labels[84][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tran = img_p\n",
    "rect = patches.Rectangle((14.2388, 15.0060), 2.7476, 2.3851, linewidth=1, edgecolor='k', facecolor='k')\n",
    "rect2 = patches.Rectangle((14.1871, 15.7513), 4.1633, 4.0735, linewidth=1, edgecolor='k', facecolor='k')\n",
    "rect3 = patches.Rectangle((15.5461,  14.7842), 3.6610, 4.1208, linewidth=1, edgecolor='w', facecolor='w')\n",
    "rect4 = patches.Rectangle((15.3920,  15.0777), 4.6964, 4.7229, linewidth=1, edgecolor='w', facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(img_p)\n",
    "ax.add_patch(rect)\n",
    "ax.add_patch(rect2)\n",
    "ax.add_patch(rect3)\n",
    "ax.add_patch(rect4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}