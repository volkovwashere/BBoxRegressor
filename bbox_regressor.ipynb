{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('deep_learning': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8277c4497ec5ba7d6314982d6cc981d386d2f2b92a732db8e35c7edb9898c80e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "from cifar10_models import mobilenetv2\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Subset, DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Net = mobilenetv2.mobilenet_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for module in Net.modules():\n",
    "#    if isinstance(module, nn.BatchNorm2d):\n",
    "#        module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for param in Net.parameters():\n",
    "#    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_allocated()/1024**2, torch.cuda.memory_cached()/1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, train_x, train_y):\n",
    "        self.data = train_x \n",
    "        self.target = train_y \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, pretrainedModel):\n",
    "        super().__init__()\n",
    "        self.features = pretrainedModel.features\n",
    "        \n",
    "        self.Flatten = nn.Flatten()\n",
    "        self.FC1 = nn.Linear(20480, 32)\n",
    "        #self.FC2 = nn.Linear(128, 64)\n",
    "        #self.FC3 = nn.Linear(64, 32)\n",
    "        #self.FC4 = nn.Linear(32, 32)\n",
    "\n",
    "\n",
    "        self.Dropout2D = nn.Dropout2d(p=0.2)\n",
    "        self.Dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "\n",
    "        self.outLayer1 = nn.Linear(32, 4)\n",
    "        self.outLayer2 = nn.Linear(32, 4)\n",
    "        self.outLayer3 = nn.Linear(32, 4)\n",
    "        self.outLayer4 = nn.Linear(32, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.Dropout2D(self.features(x))\n",
    "        x = self.Flatten(x) # flatten out the last conv layer\n",
    "\n",
    "        x = self.Dropout(torch.selu(self.FC1(x)))# use dropout with p=0.2\n",
    "        #x = self.Dropout(torch.selu(self.FC2(x)))\n",
    "        #x = self.Dropout(torch.selu(self.FC3(x)))\n",
    "        #x = self.Dropout(torch.selu(self.FC4(x)))\n",
    "\n",
    "        out1 = self.outLayer1(x)\n",
    "        out2 = self.outLayer2(x)\n",
    "        out3 = self.outLayer3(x)\n",
    "        out4 = self.outLayer4(x)\n",
    "\n",
    "        return out1, out2, out3, out4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.CIFAR10('../data-unversioned/p1ch7/', train=True, transform=preprocess, download=False)\n",
    "imgs = os.listdir('data/training')\n",
    "imgs.sort()\n",
    "indices = [int(name[0:5]) for name in imgs]\n",
    "my_subset = Subset(dataset, indices) #create subset based on indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "for data, label in my_subset:\n",
    "    train_x.append(data)\n",
    "train_x = torch.stack(train_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.from_numpy(np.load('data/labels.npy')).float()\n",
    "b = labels == 0\n",
    "indices = b.nonzero()[..., 0]\n",
    "index = torch.ones(labels.shape[0], dtype=bool)\n",
    "index[indices] = False\n",
    "\n",
    "labels = labels[index]\n",
    "labels = labels.to(device=device)\n",
    "train_x = train_x[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TrainSet = MyDataset(train_x, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(TrainSet, batch_size=64, shuffle=True) \n",
    "model = RegressionModel(Net).to(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoULoss(predictions, ground_truth):\n",
    "    P_x = predictions[..., 0:1]\n",
    "    P_y = predictions[..., 1:2]\n",
    "    P_h = predictions[..., 2:3]\n",
    "    P_w = predictions[..., 3:4]\n",
    "    G_x = ground_truth[..., 0:1]\n",
    "    G_y = ground_truth[..., 1:2]\n",
    "    G_h = ground_truth[..., 2:3]\n",
    "    G_w = ground_truth[..., 3:4]\n",
    "\n",
    "    w_intersection = torch.min(P_x + P_w, G_x + G_w) - torch.max(P_x, G_x)\n",
    "    h_intersection = torch.min(P_y + P_h, G_y + G_h) - torch.max(P_y, G_y)\n",
    "    intersection = w_intersection.clamp(0) * h_intersection.clamp(0)#if no intersection, value will default to 0\n",
    "   \n",
    "    union = P_h * P_w + G_h * G_w - intersection\n",
    "    IoU = (intersection + 1e-6)/(union + 1e-6)\n",
    "\n",
    "    ##central points\n",
    "    central_p_x = (P_x + P_w)/2\n",
    "    central_p_y = (P_y + P_h)/2\n",
    "    central_l_x = (G_x + G_w)/2\n",
    "    central_l_y = (G_y + G_h)/2\n",
    "    euc_dist = torch.sqrt(torch.square(central_l_x - central_p_x) + torch.square(central_l_y - central_p_y))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #get diagional\n",
    "    w_union = torch.max(P_x + P_w, G_x + G_w) - torch.min(P_x, G_x)\n",
    "    h_union = torch.max(P_y + P_h, G_y + G_h) - torch.min(P_y, G_y)\n",
    "    c_diag = torch.sqrt(torch.square(w_union) + torch.square(h_union))\n",
    "\n",
    "    #penalty term\n",
    "    penalty_term = euc_dist/c_diag\n",
    "\n",
    "    DistanceIoULoss = 1 - IoU + penalty_term\n",
    "\n",
    "    return DistanceIoULoss.mean()\n",
    "\n",
    "def CIoULoss(predictions, ground_truth):\n",
    "    P_x = predictions[..., 0:1]\n",
    "    P_y = predictions[..., 1:2]\n",
    "    P_h = predictions[..., 2:3]\n",
    "    P_w = predictions[..., 3:4]\n",
    "    G_x = ground_truth[..., 0:1]\n",
    "    G_y = ground_truth[..., 1:2]\n",
    "    G_h = ground_truth[..., 2:3]\n",
    "    G_w = ground_truth[..., 3:4]\n",
    "\n",
    "    w_intersection = torch.min(P_x + P_w, G_x + G_w) - torch.max(P_x, G_x)\n",
    "    h_intersection = torch.min(P_y + P_h, G_y + G_h) - torch.max(P_y, G_y)\n",
    "    intersection = w_intersection.clamp(0) * h_intersection.clamp(0)#if no intersection, value will default to 0\n",
    "   \n",
    "    union = P_h * P_w + G_h * G_w - intersection\n",
    "    IoU = (intersection + 1e-6)/(union + 1e-6)\n",
    "\n",
    "    ##central points\n",
    "    central_p_x = (P_x + P_w)/2\n",
    "    central_p_y = (P_y + P_h)/2\n",
    "    central_l_x = (G_x + G_w)/2\n",
    "    central_l_y = (G_y + G_h)/2\n",
    "    euc_dist = torch.sqrt(torch.square(central_l_x - central_p_x) + torch.square(central_l_y - central_p_y))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #get diagional\n",
    "    w_union = torch.max(P_x + P_w, G_x + G_w) - torch.min(P_x, G_x)\n",
    "    h_union = torch.max(P_y + P_h, G_y + G_h) - torch.min(P_y, G_y)\n",
    "    c_diag = torch.sqrt(torch.square(w_union) + torch.square(h_union))\n",
    "\n",
    "    #penalty term\n",
    "    penalty_term = euc_dist/c_diag\n",
    "\n",
    "\n",
    "    #aspect ratio\n",
    "    pi = torch.acos(torch.zeros(1)).item() * 2\n",
    "    v = 4/(pi**2) * torch.square(torch.atan(G_w/G_h) - torch.atan(P_w/P_h)) #aspect ratio\n",
    "    alpha =  v/((1 - IoU) + v)\n",
    " \n",
    "\n",
    "    CompleteIoULoss = 1 - IoU + penalty_term + (alpha * v)\n",
    "\n",
    "    return CompleteIoULoss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_d = IoULoss\n",
    "loss_c = CIoULoss\n",
    "loss_quad = nn.MSELoss()\n",
    "loss_abs = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_labels_correctly(label_batch):\n",
    "    l1 = torch.stack([label[0] for label in label_batch])\n",
    "    l2 = torch.stack([label[1] for label in label_batch])\n",
    "    l3 = torch.stack([label[2] for label in label_batch])\n",
    "    l4 = torch.stack([label[3] for label in label_batch])\n",
    "\n",
    "    return l1, l2, l3, l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_IoU, loss_abs, loader, batch_size: int):    \n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        running_loss = 0.0\n",
    "        idx = 0\n",
    "        for img_batch, labels in loader:\n",
    "            img_batch = img_batch.to(device=device)\n",
    "            out1, out2, out3, out4 = model(img_batch)\n",
    "            #out1 = model(img_batch)\n",
    "            label1, label2, label3, label4 = arrange_labels_correctly(labels)\n",
    "            \n",
    "            loss1 = loss_IoU(out1, label1) + loss_abs(out1, label1)\n",
    "            loss2 = loss_IoU(out2, label2) + loss_abs(out2, label2) \n",
    "            loss3 = loss_IoU(out3, label3) + loss_abs(out3, label3)\n",
    "            loss4 = loss_IoU(out4, label4) + loss_abs(out4, label4)\n",
    "\n",
    "            #loss_total = loss1\n",
    "            #print(loss_total)\n",
    "            loss_total = (loss1 + loss2 + loss3 + loss4)#accumulate loss \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_total.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss_total.item() * img_batch.size(0)\n",
    "            \n",
    "            if idx % 400 == 0:\n",
    "                print(f'step {idx} is the current iteration and loss is: {loss_total}')\n",
    "\n",
    "            idx += 1\n",
    "            \n",
    "        \n",
    "        epoch_loss = running_loss / len(TrainSet)\n",
    "        print(f'At epoch: {epoch}, the training loss is {epoch_loss}')\n",
    "        losses.append(epoch_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop(n_epochs=21, optimizer=optimizer, model=model, loss_IoU=loss_d, loss_abs=loss_abs, loader=train_loader, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_loop(n_epochs=12, optimizer=optimizer, model=model, loss_fn=loss_quad, loader=train_loader, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop(n_epochs=20, optimizer=optimizer, model=model, loss_fn=loss_c, loader=train_loader, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop(n_epochs=30, optimizer=optimizer, model=model, loss_fn=loss, loader=train_loader, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgbatch, labels in train_loader:\n",
    "    o1 = model(imgbatch.to(device=device))\n",
    "    \n",
    "    asd = labels\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(o1, l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = torch.stack([a[0][:2] for a in asd])\n",
    "l1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels[0], l1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "del labels\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd2 = my_subset[974][0].to(device=device)\n",
    "asd3 = my_subset[1852][0].to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(torch.unsqueeze(asd2, 0)), model(torch.unsqueeze(asd3, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[974][0], labels[1852][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_p = asd2\n",
    "rect = patches.Rectangle((14.2388, 15.0060), 2.7476, 2.3851, linewidth=1, edgecolor='k', facecolor='k')\n",
    "#rect2 = patches.Rectangle((14.1871, 15.7513), 4.1633, 4.0735, linewidth=1, edgecolor='k', facecolor='k')\n",
    "#rect3 = patches.Rectangle((15.5461,  14.7842), 3.6610, 4.1208, linewidth=1, edgecolor='w', facecolor='w')\n",
    "#rect4 = patches.Rectangle((15.3920,  15.0777), 4.6964, 4.7229, linewidth=1, edgecolor='w', facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(img_p)\n",
    "ax.add_patch(rect)\n",
    "ax.add_patch(rect2)\n",
    "ax.add_patch(rect3)\n",
    "ax.add_patch(rect4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}