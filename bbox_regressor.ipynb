{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('deep_learning': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8277c4497ec5ba7d6314982d6cc981d386d2f2b92a732db8e35c7edb9898c80e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "from cifar10_models import mobilenetv2\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Net = mobilenetv2.mobilenet_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in Net.modules():\n",
    "    if isinstance(module, nn.BatchNorm2d):\n",
    "        module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for param in Net.parameters():\n",
    "#    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()/1024**2, torch.cuda.memory_cached()/1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, pretrainedModel):\n",
    "        super().__init__()\n",
    "        self.features = pretrainedModel.features\n",
    "        \n",
    "        self.Flatten = nn.Flatten()\n",
    "        self.FC1 = nn.Linear(20480, 256)\n",
    "        self.FC2 = nn.Linear(256, 128)\n",
    "        self.FC3 = nn.Linear(128, 64)\n",
    "        self.FC4 = nn.Linear(64, 32)\n",
    "\n",
    "\n",
    "        self.Dropout2D = nn.Dropout2d(p=0.2)\n",
    "        self.Dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "\n",
    "        self.outLayer1 = nn.Linear(32, 4)\n",
    "        self.outLayer2 = nn.Linear(32, 4)\n",
    "        self.outLayer3 = nn.Linear(32, 4)\n",
    "        self.outLayer4 = nn.Linear(32, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.Dropout2D(self.features(x))\n",
    "        x = self.Flatten(x) # flatten out the last conv layer\n",
    "\n",
    "        x = self.Dropout(torch.selu(self.FC1(x)))# use dropout with p=0.2\n",
    "        x = self.Dropout(torch.selu(self.FC2(x)))\n",
    "        x = self.Dropout(torch.selu(self.FC3(x)))\n",
    "        x = self.Dropout(torch.selu(self.FC4(x)))\n",
    "\n",
    "        out1 = self.outLayer1(x)\n",
    "        out2 = self.outLayer2(x)\n",
    "        out3 = self.outLayer3(x)\n",
    "        out4 = self.outLayer4(x)\n",
    "\n",
    "        return out1, out2, out3, out4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.CIFAR10('../data-unversioned/p1ch7/', train=True, transform=preprocess, download=False)\n",
    "imgs = os.listdir('data/training')\n",
    "imgs.sort()\n",
    "indices = [int(name[0:5]) for name in imgs]\n",
    "my_subset = Subset(dataset, indices) #create subset based on indices\n",
    "train_loader = DataLoader(my_subset, batch_size=1, shuffle=False) #shuffle false so we can use correct stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.from_numpy(np.load('data/labels.npy')).float()\n",
    "labels = labels.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RegressionModel(Net).to(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([4]), torch.Size([1, 4]))"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "img = cv2.imread('data/attacks/00000_input_img.png')\n",
    "imgT = torch.tensor(img)\n",
    "imgT = imgT.view(3, 32 , 32).to(device=device)\n",
    "imgT = torch.unsqueeze(imgT, 0).float()\n",
    "out1, out2, out3, out4 = model(imgT)\n",
    "model.train()\n",
    "out1[0].shape, out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, loader, labels):    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        loss_train = 0.0\n",
    "        idx = 0\n",
    "        for img_batch, _ in loader:\n",
    "            \n",
    "            img_batch = img_batch.to(device=device)\n",
    "            out1, out2, out3, out4 = model(img_batch)\n",
    "            loss1 = loss_fn(out1[0], labels[idx][0])\n",
    "            loss2 = loss_fn(out2[0], labels[idx][1])\n",
    "            loss3 = loss_fn(out3[0], labels[idx][2])\n",
    "            loss4 = loss_fn(out4[0], labels[idx][3])\n",
    "\n",
    "            loss_total = (loss1 + loss2 + loss3 + loss4) #accumulate loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_total.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            \n",
    "            \n",
    "            if idx % 400 == 0:\n",
    "                print(f'step {idx} is the current iteration and loss is: {loss_total}')\n",
    "\n",
    "            idx += 1\n",
    "        \n",
    "        print(f'At epoch: {epoch}, the training loss is {loss_total}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step 0 is the current iteration and loss is: 598.6073608398438\n",
      "step 400 is the current iteration and loss is: 159.17478942871094\n",
      "step 800 is the current iteration and loss is: 249.94680786132812\n",
      "step 1200 is the current iteration and loss is: 54.236473083496094\n",
      "step 1600 is the current iteration and loss is: 133.2995147705078\n",
      "step 2000 is the current iteration and loss is: 223.1544952392578\n",
      "step 2400 is the current iteration and loss is: 82.50814819335938\n",
      "step 2800 is the current iteration and loss is: 48.13749694824219\n",
      "step 3200 is the current iteration and loss is: 69.76011657714844\n",
      "step 3600 is the current iteration and loss is: 112.3565444946289\n",
      "step 4000 is the current iteration and loss is: 119.34650421142578\n",
      "step 4400 is the current iteration and loss is: 72.93921661376953\n",
      "At epoch: 1, the training loss is 102.05825805664062\n",
      "step 0 is the current iteration and loss is: 139.89503479003906\n",
      "step 400 is the current iteration and loss is: 59.45940399169922\n",
      "step 800 is the current iteration and loss is: 221.60926818847656\n",
      "step 1200 is the current iteration and loss is: 72.66680145263672\n",
      "step 1600 is the current iteration and loss is: 151.99990844726562\n",
      "step 2000 is the current iteration and loss is: 228.7373809814453\n",
      "step 2400 is the current iteration and loss is: 81.628662109375\n",
      "step 2800 is the current iteration and loss is: 52.10161590576172\n",
      "step 3200 is the current iteration and loss is: 62.899993896484375\n",
      "step 3600 is the current iteration and loss is: 76.45124053955078\n",
      "step 4000 is the current iteration and loss is: 109.38720703125\n",
      "step 4400 is the current iteration and loss is: 122.40036010742188\n",
      "At epoch: 2, the training loss is 136.8866424560547\n"
     ]
    }
   ],
   "source": [
    "training_loop(n_epochs=2, optimizer=optimizer, model=model, loss_fn=loss, loader=train_loader, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = my_subset[5][0].to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "del labels\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd2 = my_subset[16][0].to(device=device)\n",
    "asd3 = my_subset[67][0].to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((tensor([[13.0863, 14.7098,  2.8455,  2.4467]], device='cuda:0',\n",
       "         grad_fn=<AddmmBackward>),\n",
       "  tensor([[13.3207, 14.1652,  4.0221,  3.7565]], device='cuda:0',\n",
       "         grad_fn=<AddmmBackward>),\n",
       "  tensor([[13.8847, 14.1954,  3.6099,  3.4445]], device='cuda:0',\n",
       "         grad_fn=<AddmmBackward>),\n",
       "  tensor([[14.3875, 13.7179,  4.3074,  4.3675]], device='cuda:0',\n",
       "         grad_fn=<AddmmBackward>)),\n",
       " (tensor([[13.5272, 15.1986,  2.8975,  2.5543]], device='cuda:0',\n",
       "         grad_fn=<AddmmBackward>),\n",
       "  tensor([[13.6988, 14.6159,  4.1145,  3.8615]], device='cuda:0',\n",
       "         grad_fn=<AddmmBackward>),\n",
       "  tensor([[14.3594, 14.6630,  3.6989,  3.5497]], device='cuda:0',\n",
       "         grad_fn=<AddmmBackward>),\n",
       "  tensor([[14.7970, 14.1685,  4.4152,  4.4691]], device='cuda:0',\n",
       "         grad_fn=<AddmmBackward>)))"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "model(torch.unsqueeze(asd2, 0)), model(torch.unsqueeze(asd3, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[21.6715, 19.8500,  5.0000,  3.8596],\n",
       "        [16.2501, 26.6525,  5.0000,  5.0000],\n",
       "        [12.6542, 22.0432,  5.0000,  3.9232],\n",
       "        [ 5.7360,  9.2632,  5.0000,  4.9370]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}